"""
Constants v√† c·∫•u h√¨nh cho Study Buddy
"""

# File types ƒë∆∞·ª£c h·ªó tr·ª£
SUPPORTED_FILE_TYPES = {
    'pdf': 'application/pdf',
    'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    'txt': 'text/plain',
    'md': 'text/markdown'
}

# Gi·ªõi h·∫°n file
MAX_FILE_SIZE = 200 * 1024 * 1024  # 200MB
MAX_FILE_NAME_LENGTH = 255
MIN_FILE_SIZE = 1  # 1 byte

# C·∫•u h√¨nh chat
MAX_MESSAGE_LENGTH = 10000
MAX_MESSAGES_PER_SESSION = 1000
MAX_CHAT_HISTORY = 50

# C·∫•u h√¨nh document processing
MAX_DOCUMENT_CHARS = 1000000  # 1M chars
MIN_SUMMARY_LENGTH = 50
MAX_SUMMARY_LENGTH = 500
MAX_QUESTIONS_COUNT = 6
MIN_QUESTIONS_COUNT = 3

# OCR settings
DEFAULT_PDF_DPI = 150
MAX_PDF_DPI = 300
MIN_PDF_DPI = 72

# Database settings
MAX_SESSION_TITLE_LENGTH = 100
MAX_CONTENT_LENGTH = 50000
DB_TIMEOUT = 30  # seconds

# Enhanced LLM settings v·ªõi advanced configurations
LOCAL_LLM_DEFAULT_URL = "http://localhost:1234/v1"
MAX_LLM_TOKENS = 2000
DEFAULT_TEMPERATURE = 0.7
MAX_CONTEXT_LENGTH = 4000

# Advanced LLM parameters
LLM_GENERATION_CONFIG = {
    'chat': {
        'temperature': 0.6,
        'top_p': 0.9,
        'max_tokens': 1200,
        'frequency_penalty': 0.1,
        'presence_penalty': 0.1
    },
    'document_qa': {
        'temperature': 0.15,
        'top_p': 0.8,
        'max_tokens': 600,
        'frequency_penalty': 0.0,
        'presence_penalty': 0.0
    },
    'summarization': {
        'temperature': 0.3,
        'top_p': 0.85,
        'max_tokens': 400,
        'frequency_penalty': 0.2,
        'presence_penalty': 0.1
    }
}

# Smart retry configurations
RETRY_CONFIG = {
    'llm_operations': {
        'max_retries': 2,
        'base_delay': 1.0,
        'backoff_factor': 1.5,
        'rate_limit_delay': 2.0
    },
    'file_processing': {
        'max_retries': 3,
        'base_delay': 0.5,
        'backoff_factor': 2.0,
        'rate_limit_delay': 1.0
    },
    'database_operations': {
        'max_retries': 3,
        'base_delay': 0.3,
        'backoff_factor': 1.2,
        'rate_limit_delay': 0.5
    }
}

# Performance optimization settings
PERFORMANCE_CONFIG = {
    'context_management': {
        'max_history_messages': 12,
        'relevant_context_length': 2000,
        'smart_filtering_enabled': True,
        'context_compression_ratio': 0.7
    },
    'document_processing': {
        'chunk_size': 1000,
        'chunk_overlap': 200,
        'batch_processing_size': 3,
        'parallel_processing': False,
        'smart_chunking': True
    },
    'caching': {
        'enable_response_cache': True,
        'enable_document_cache': True,
        'cache_ttl_minutes': 60,
        'max_cache_items': 100
    }
}

# Enhanced error messages v·ªõi context-aware messaging
ERROR_MESSAGES = {
    # File processing errors
    'file_too_large': 'File qu√° l·ªõn. K√≠ch th∆∞·ªõc t·ªëi ƒëa l√† {max_size}MB.',
    'file_too_small': 'File qu√° nh·ªè. K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu l√† {min_size} bytes.',
    'unsupported_format': 'ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Ch·ªâ h·ªó tr·ª£: {formats}.',
    'file_name_too_long': 'T√™n file qu√° d√†i. T·ªëi ƒëa {max_length} k√Ω t·ª±.',
    'upload_failed': 'Upload file th·∫•t b·∫°i. Vui l√≤ng th·ª≠ l·∫°i.',
    'processing_failed': 'X·ª≠ l√Ω t√†i li·ªáu th·∫•t b·∫°i. Vui l√≤ng ki·ªÉm tra file.',
    'file_corrupted': 'File b·ªã l·ªói ho·∫∑c kh√¥ng ƒë·∫ßy ƒë·ªß. Vui l√≤ng ki·ªÉm tra v√† upload l·∫°i.',
    
    # OCR and document processing
    'ocr_failed': 'OCR PDF th·∫•t b·∫°i. File c√≥ th·ªÉ b·ªã l·ªói ho·∫∑c kh√¥ng c√≥ text.',
    'pdf_password_protected': 'PDF ƒë∆∞·ª£c b·∫£o v·ªá b·ªüi m·∫≠t kh·∫©u. Vui l√≤ng m·ªü kh√≥a tr∆∞·ªõc khi upload.',
    'pdf_no_text': 'PDF kh√¥ng ch·ª©a text c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c.',
    'document_too_long': 'T√†i li·ªáu qu√° d√†i ƒë·ªÉ x·ª≠ l√Ω. Vui l√≤ng chia nh·ªè ho·∫∑c ch·ªçn ph·∫ßn c·∫ßn thi·∫øt.',
    
    # LLM connection errors v·ªõi detailed guidance
    'llm_connection_failed': 'Kh√¥ng th·ªÉ k·∫øt n·ªëi Local LLM. Ki·ªÉm tra LM Studio ƒëang ch·∫°y.',
    'llm_model_not_loaded': 'Local LLM ch∆∞a load model. Vui l√≤ng kh·ªüi ƒë·ªông LM Studio v√† load model.',
    'llm_connection_timeout': 'K·∫øt n·ªëi Local LLM timeout. Model c√≥ th·ªÉ qu√° l·ªõn cho h·ªá th·ªëng.',
    'llm_generation_failed': 'LLM kh√¥ng th·ªÉ t·∫°o ph·∫£n h·ªìi. Th·ª≠ v·ªõi c√¢u h·ªèi ƒë∆°n gi·∫£n h∆°n.',
    'llm_context_overflow': 'N·ªôi dung qu√° d√†i cho LLM x·ª≠ l√Ω. Vui l√≤ng r√∫t g·ªçn c√¢u h·ªèi.',
    'llm_server_overloaded': 'LLM server ƒëang qu√° t·∫£i. Vui l√≤ng ch·ªù v√† th·ª≠ l·∫°i.',
    
    # Database errors
    'database_connection_failed': 'L·ªói k·∫øt n·ªëi database. Vui l√≤ng th·ª≠ l·∫°i.',
    'session_create_failed': 'Kh√¥ng th·ªÉ t·∫°o session chat m·ªõi.',
    'message_save_failed': 'Kh√¥ng th·ªÉ l∆∞u tin nh·∫Øn.',
    'data_corruption': 'D·ªØ li·ªáu b·ªã l·ªói. Vui l√≤ng kh·ªüi t·∫°o l·∫°i session.',
    'storage_full': 'Dung l∆∞·ª£ng l∆∞u tr·ªØ ƒë√£ ƒë·∫ßy. Vui l√≤ng x√≥a d·ªØ li·ªáu c≈©.',
    
    # Authentication and session
    'authentication_required': 'Vui l√≤ng ƒëƒÉng nh·∫≠p ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y.',
    'invalid_session': 'Session kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n.',
    'session_expired': 'Phi√™n l√†m vi·ªác ƒë√£ h·∫øt h·∫°n. Vui l√≤ng ƒëƒÉng nh·∫≠p l·∫°i.',
    'unauthorized_access': 'Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p t√†i nguy√™n n√†y.',
    
    # Input validation
    'message_too_long': 'Tin nh·∫Øn qu√° d√†i. T·ªëi ƒëa {max_length} k√Ω t·ª±.',
    'too_many_messages': 'Qu√° nhi·ªÅu tin nh·∫Øn trong session. T·ªëi ƒëa {max_count} tin nh·∫Øn.',
    'invalid_page_number': 'S·ªë trang kh√¥ng h·ª£p l·ªá. Ph·∫£i t·ª´ 1 ƒë·∫øn {max_pages}.',
    'empty_input': 'Vui l√≤ng nh·∫≠p n·ªôi dung tr∆∞·ªõc khi g·ª≠i.',
    'invalid_format': 'ƒê·ªãnh d·∫°ng d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá.',
    
    # Network and API errors
    'network_error': 'L·ªói k·∫øt n·ªëi m·∫°ng. Vui l√≤ng ki·ªÉm tra internet.',
    'timeout_error': 'Thao t√°c timeout. Vui l√≤ng th·ª≠ l·∫°i.',
    'api_rate_limit': 'API ƒë√£ v∆∞·ª£t gi·ªõi h·∫°n rate limit. Vui l√≤ng ch·ªù v√† th·ª≠ l·∫°i.',
    'service_unavailable': 'D·ªãch v·ª• t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng th·ª≠ l·∫°i sau.',
    'mistral_api_limit': 'Mistral API ƒë√£ v∆∞·ª£t gi·ªõi h·∫°n. Vui l√≤ng th·ª≠ l·∫°i sau.',
    'mistral_api_auth': 'Mistral API key kh√¥ng h·ª£p l·ªá. Ki·ªÉm tra c·∫•u h√¨nh.',
    
    # System errors
    'permission_denied': 'Kh√¥ng c√≥ quy·ªÅn th·ª±c hi·ªán thao t√°c n√†y.',
    'resource_not_found': 'Kh√¥ng t√¨m th·∫•y t√†i nguy√™n ƒë∆∞·ª£c y√™u c·∫ßu.',
    'system_overload': 'H·ªá th·ªëng ƒëang qu√° t·∫£i. Vui l√≤ng th·ª≠ l·∫°i sau.',
    'maintenance_mode': 'H·ªá th·ªëng ƒëang b·∫£o tr√¨. Vui l√≤ng quay l·∫°i sau.',
    'unexpected_error': 'L·ªói kh√¥ng mong mu·ªën. Vui l√≤ng b√°o c√°o cho admin.'
}

# Success messages
SUCCESS_MESSAGES = {
    'file_uploaded': 'Upload file th√†nh c√¥ng: {filename}',
    'document_processed': 'X·ª≠ l√Ω t√†i li·ªáu th√†nh c√¥ng',
    'session_created': 'T·∫°o cu·ªôc tr√≤ chuy·ªán m·ªõi th√†nh c√¥ng',
    'message_sent': 'G·ª≠i tin nh·∫Øn th√†nh c√¥ng',
    'login_success': 'ƒêƒÉng nh·∫≠p th√†nh c√¥ng',
    'logout_success': 'ƒêƒÉng xu·∫•t th√†nh c√¥ng',
    'account_created': 'T·∫°o t√†i kho·∫£n th√†nh c√¥ng',
    'session_deleted': 'X√≥a cu·ªôc tr√≤ chuy·ªán th√†nh c√¥ng',
    'document_deleted': 'X√≥a t√†i li·ªáu th√†nh c√¥ng'
}

# Warning messages
WARNING_MESSAGES = {
    'large_file': 'File kh√° l·ªõn, vi·ªác x·ª≠ l√Ω c√≥ th·ªÉ m·∫•t th·ªùi gian.',
    'many_pages': 'PDF c√≥ nhi·ªÅu trang, OCR c√≥ th·ªÉ ch·∫≠m.',
    'llm_offline': 'LLM offline, ch·∫°y ·ªü ch·∫ø ƒë·ªô demo.',
    'no_internet': 'Kh√¥ng c√≥ k·∫øt n·ªëi internet.',
    'beta_feature': 'ƒê√¢y l√† t√≠nh nƒÉng beta, c√≥ th·ªÉ kh√¥ng ·ªïn ƒë·ªãnh.',
    'data_loss': 'D·ªØ li·ªáu c√≥ th·ªÉ b·ªã m·∫•t n·∫øu kh√¥ng l∆∞u.',
    'session_limit': 'G·∫ßn ƒë·∫°t gi·ªõi h·∫°n s·ªë session.',
    'storage_limit': 'Dung l∆∞·ª£ng l∆∞u tr·ªØ g·∫ßn h·∫øt.'
}

# Regex patterns
PATTERNS = {
    'email': r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$',
    'username': r'^[a-zA-Z0-9_]{3,20}$',
    'filename': r'^[a-zA-Z0-9._-]+$',
    'uuid': r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$'
}

# Default values
DEFAULTS = {
    'chat_title': 'Cu·ªôc tr√≤ chuy·ªán m·ªõi',
    'user_avatar': 'üë§',
    'assistant_avatar': 'ü§ñ',
    'session_timeout': 3600,  # 1 hour
    'auto_save_interval': 30,  # 30 seconds
    'max_retry_attempts': 3,
    'retry_delay': 1.0  # seconds
}

# Enhanced feature flags v·ªõi granular control
FEATURES = {
    # Core features
    'enable_ocr': True,
    'enable_rag': True,
    'enable_chat_export': True,
    'enable_document_cache': True,
    'enable_session_persistence': True,
    'enable_auto_save': True,
    'enable_offline_mode': True,
    
    # Advanced features
    'enable_smart_context_management': True,
    'enable_intelligent_retry': True,
    'enable_adaptive_chunking': True,
    'enable_response_caching': True,
    'enable_error_recovery': True,
    'enable_performance_monitoring': True,
    'enable_progressive_loading': True,
    'enable_context_compression': True,
    
    # UI/UX enhancements
    'enable_progress_tracking': True,
    'enable_eta_calculation': True,
    'enable_smart_suggestions': True,
    'enable_typing_indicators': True,
    'enable_message_reactions': False,
    
    # Development and debugging
    'enable_debug_mode': False,
    'enable_telemetry': False,
    'enable_performance_profiling': False,
    'enable_error_reporting': True,
    'enable_usage_analytics': False,
    
    # Experimental features
    'enable_multi_model_support': False,
    'enable_voice_input': False,
    'enable_real_time_collaboration': False,
    'enable_advanced_search': False
}

# Model-specific configurations
MODEL_CONFIGS = {
    'llama': {
        'recommended_params': {
            'temperature': 0.7,
            'top_p': 0.9,
            'max_tokens': 1000
        },
        'context_window': 4096,
        'best_use_cases': ['general_chat', 'code_assistance']
    },
    'mistral': {
        'recommended_params': {
            'temperature': 0.6,
            'top_p': 0.85,
            'max_tokens': 1200
        },
        'context_window': 8192,
        'best_use_cases': ['document_qa', 'summarization']
    },
    'phi': {
        'recommended_params': {
            'temperature': 0.5,
            'top_p': 0.8,
            'max_tokens': 800
        },
        'context_window': 2048,
        'best_use_cases': ['quick_responses', 'mobile_deployment']
    }
}

# API endpoints (n·∫øu c√≥ external APIs)
API_ENDPOINTS = {
    'mistral_ocr': 'https://api.mistral.ai/v1/ocr',
    'local_llm': LOCAL_LLM_DEFAULT_URL,
    'supabase': '',  # S·∫Ω ƒë∆∞·ª£c set t·ª´ environment
}

# Cache settings
CACHE_SETTINGS = {
    'ttl': 3600,  # 1 hour
    'max_size': 100,  # s·ªë items
    'cleanup_interval': 300  # 5 minutes
}
