import streamlit as st
import os
from datetime import datetime
from utils.document_processor import DocumentProcessor
from utils.chat_handler import ChatHandler
from utils.ui_components import render_message, render_sidebar

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="ChatGPT Clone",
    page_icon="üí¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Load CSS t√πy ch·ªânh
def load_css():
    with open("styles/style.css") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

# Kh·ªüi t·∫°o session state
def init_session_state():
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "uploaded_documents" not in st.session_state:
        st.session_state.uploaded_documents = []
    if "chat_handler" not in st.session_state:
        st.session_state.chat_handler = ChatHandler()
    if "doc_processor" not in st.session_state:
        st.session_state.doc_processor = DocumentProcessor()
    if "document_summary" not in st.session_state:
        st.session_state.document_summary = ""
    if "suggested_questions" not in st.session_state:
        st.session_state.suggested_questions = []
    if "document_embeddings" not in st.session_state:
        st.session_state.document_embeddings = []
    if "document_text" not in st.session_state:
        st.session_state.document_text = ""

def main():
    # Load CSS v√† kh·ªüi t·∫°o
    try:
        load_css()
    except FileNotFoundError:
        pass  # CSS file ch∆∞a t·ªìn t·∫°i
    
    init_session_state()
    
    # Sidebar
    with st.sidebar:
        st.title("üí¨ ChatGPT Clone")
        
        # Upload t√†i li·ªáu
        st.header("üìÑ Upload T√†i li·ªáu")
        uploaded_file = st.file_uploader(
            "Ch·ªçn t√†i li·ªáu",
            type=['pdf', 'docx', 'txt', 'md'],
            help="H·ªó tr·ª£ PDF, DOCX, TXT, MD"
        )
        
        if uploaded_file is not None:
            # Ki·ªÉm tra xem file ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ch∆∞a b·∫±ng t√™n v√† k√≠ch th∆∞·ªõc
            file_already_processed = False
            for doc in st.session_state.uploaded_documents:
                if (doc["file"].name == uploaded_file.name and 
                    doc["file"].size == uploaded_file.size):
                    file_already_processed = True
                    break
            
            if not file_already_processed:
                with st.spinner("ƒêang x·ª≠ l√Ω t√†i li·ªáu..."):
                    doc_content = st.session_state.doc_processor.process_document(uploaded_file)
                    if doc_content:
                        # T√≥m t·∫Øt t√†i li·ªáu
                        with st.spinner("ƒêang t√≥m t·∫Øt t√†i li·ªáu..."):
                            summary = st.session_state.doc_processor.summarize_text(doc_content)
                            st.session_state.document_summary = summary
                        
                        # T·∫°o c√¢u h·ªèi g·ª£i √Ω
                        with st.spinner("ƒêang t·∫°o c√¢u h·ªèi g·ª£i √Ω..."):
                            questions = st.session_state.doc_processor.generate_questions(doc_content)
                            st.session_state.suggested_questions = questions
                        
                        # Cache document text ƒë·ªÉ t√°i s·ª≠ d·ª•ng
                        st.session_state.document_text = doc_content
                        st.session_state.document_embeddings = []
                        
                        st.session_state.uploaded_documents.append({
                            "file": uploaded_file,
                            "content": doc_content,
                            "timestamp": datetime.now(),
                            "summary": summary,
                            "questions": questions
                        })
                        st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω xong: {uploaded_file.name}")
        
        # Hi·ªÉn th·ªã t√†i li·ªáu ƒë√£ upload
        if st.session_state.uploaded_documents:
            st.header("üìö T√†i li·ªáu ƒë√£ t·∫£i")
            for i, doc in enumerate(st.session_state.uploaded_documents):
                with st.expander(f"üìÑ {doc['file'].name}"):
                    st.write(f"**K√≠ch th∆∞·ªõc:** {doc['file'].size} bytes")
                    st.write(f"**Th·ªùi gian:** {doc['timestamp'].strftime('%H:%M %d/%m/%Y')}")
                    st.write(f"**N·ªôi dung:** {len(doc['content'])} k√Ω t·ª±")
                    
                    # Hi·ªÉn th·ªã t√≥m t·∫Øt
                    if 'summary' in doc and doc['summary']:
                        st.write("**üìù T√≥m t·∫Øt:**")
                        st.info(doc['summary'])
                    else:
                        st.warning("Ch∆∞a c√≥ t√≥m t·∫Øt")
                    
                    if st.button(f"X√≥a", key=f"delete_{i}"):
                        st.session_state.uploaded_documents.pop(i)
                        # Reset document-related states
                        st.session_state.document_summary = ""
                        st.session_state.suggested_questions = []
                        st.session_state.document_text = ""
                        st.rerun()
        
        # N√∫t x√≥a l·ªãch s·ª≠ chat
        if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat"):
            st.session_state.messages = []
            st.rerun()
    
    # Main chat area
    st.title("ChatGPT Clone v·ªõi Upload T√†i li·ªáu")
    
    # Hi·ªÉn th·ªã t√≥m t·∫Øt v√† c√¢u h·ªèi g·ª£i √Ω
    if st.session_state.document_summary:
        st.header("üìù T√≥m t·∫Øt t√†i li·ªáu")
        with st.container():
            st.markdown(f"**T√≥m t·∫Øt:** {st.session_state.document_summary}")
        
        st.header("‚ùì C√¢u h·ªèi g·ª£i √Ω")
        if st.session_state.suggested_questions:
            col1, col2 = st.columns(2)
            for i, question in enumerate(st.session_state.suggested_questions):
                with col1 if i % 2 == 0 else col2:
                    if st.button(f"üí¨ {question}", key=f"question_{i}", use_container_width=True):
                        # Khi user click v√†o c√¢u h·ªèi, t·ª± ƒë·ªông g·ª≠i c√¢u h·ªèi ƒë√≥
                        st.session_state.messages.append({
                            "role": "user",
                            "content": question,
                            "timestamp": datetime.now()
                        })
                        
                        # S·ª≠ d·ª•ng BART ƒë·ªÉ tr·∫£ l·ªùi d·ª±a tr√™n cached document text
                        response = st.session_state.doc_processor.answer_question_with_bart(
                            question,
                            st.session_state.document_text
                        )
                        
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": response,
                            "timestamp": datetime.now()
                        })
                        st.rerun()
        
        st.divider()
    
    # Container cho messages
    messages_container = st.container()
    
    # Hi·ªÉn th·ªã messages
    with messages_container:
        for message in st.session_state.messages:
            render_message(message)
    
    # Chat input
    if prompt := st.chat_input("Nh·∫≠p tin nh·∫Øn c·ªßa b·∫°n..."):
        # Th√™m tin nh·∫Øn c·ªßa user
        user_message = {
            "role": "user",
            "content": prompt,
            "timestamp": datetime.now()
        }
        st.session_state.messages.append(user_message)
        
        # Hi·ªÉn th·ªã tin nh·∫Øn user ngay l·∫≠p t·ª©c
        with messages_container:
            render_message(user_message)
        
        # X·ª≠ l√Ω ph·∫£n h·ªìi AI
        with st.spinner("ƒêang suy nghƒ©..."):
            # N·∫øu c√≥ document th√¨ d√πng BART, kh√¥ng th√¨ d√πng ChatHandler
            if st.session_state.document_text:
                response = st.session_state.doc_processor.answer_question_with_bart(
                    prompt,
                    st.session_state.document_text
                )
            else:
                # Fallback cho chat th√¥ng th∆∞·ªùng
                response = st.session_state.chat_handler.generate_response(
                    prompt, 
                    st.session_state.messages[:-1],
                    ""
                )
            
            # Th√™m ph·∫£n h·ªìi AI
            ai_message = {
                "role": "assistant",
                "content": response,
                "timestamp": datetime.now()
            }
            st.session_state.messages.append(ai_message)
        
        # Rerun ƒë·ªÉ hi·ªÉn th·ªã tin nh·∫Øn AI
        st.rerun()

if __name__ == "__main__":
    main()
